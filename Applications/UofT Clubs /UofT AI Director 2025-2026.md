Through my roles as an Orientation Coordinator at Trinity College and a developer at Blueprint, I’ve led both high-impact logistics and meaningful community-building. At Trinity, I’m helping oversee over $100,000 in funding and coordinating a wide range of events to welcome new students — from large-scale programming to casual socials that bring people together. At Blueprint, I led frontend development for a civic tech platform while also helping organize team events like rock climbing nights, strengthening team culture beyond just code.

I also contributed to Students Developing Software (SDS) under Prof. David Liu, where I worked on PythonTA and helped foster a strong, supportive team environment through weekly meetings and socials. Across all of these roles, I’ve learned how to build inclusive, mission-driven communities that people actually want to be part of.

As Director of Community Engagement, I’d bring that same energy to UofT AI — planning thoughtful events, championing cross-disciplinary conversations, and making AI feel accessible, exciting, and community-driven for everyone.

------------

One initiative I’d propose is creating a focused team structure with clear roles and ownership, modeled after what I’ve seen work at Trinity Orientation and Blueprint.

We’d split the 20-person team into 3–4 working groups — like Socials, External Partnerships, and Cross-Disciplinary Outreach — each led by an associate or two. These groups would take charge of planning 1–2 events each term, with support from me and the broader team.

At Trinity, managing over $100K in funding and dozens of orientation events taught me that people do their best work when they feel trusted and clear on their responsibilities. Similarly, at Blueprint, small focused groups made organizing things like rock climbing nights and tech events feel natural and collaborative.

I’d also run monthly planning syncs across teams to share updates and cross-pollinate ideas — making sure we stay aligned without micromanaging. The goal is to give every associate a chance to lead something real, while building a team culture that’s supportive, efficient, and fun.

A real-world problem AI is not well-suited to solve is value alignment in complex, high-stakes systems — especially when corporate incentives are involved.

At today’s UofT CS 60th Anniversary talk, I had the chance to attend as part of Prof. David Liu’s Students Developing Software (SDS) team. He spoke powerfully about how today’s AI systems don’t understand values — they optimize for goals, not meaning — and how that disconnect becomes dangerous when deployed by powerful actors like corporations that prioritize growth over ethics.

It reminded me that AI isn’t inherently wise or neutral. When used in contexts like justice, education, or public policy — areas that require nuance, empathy, and long-term responsibility — AI’s lack of true value alignment can lead to outcomes that are efficient but harmful. Solving this isn’t just a technical problem; it’s a societal one.